==========------- Docker | notes -------==========
~~~~~~~~~~ Install Docker ~~~~~~~~~~
* https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-20-04
1. Update existing list of packages
  $ sudo apt update
2. Install prerequisite packages which let apt use packages over HTTPS
  $ sudo apt install apt-transport-https ca-certificates curl software-properties-common
3. Add the GPG key for the official Docker repository to your system
  $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
4. Add the Docker repository to APT sources. This will also update our package database with the Docker packages from the newly added repo.
  $ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable"
5. Make sure you are about to install from the Docker repo instead of the default Ubuntu repo
  $ apt-cache policy docker-ce
  // The 'focal' is the important part to see in output: Candidate: 5:27.3.1-1~ubuntu.20.04~focal
6. Finally, install Docker
  $ sudo apt install docker-ce
// Docker should now be installed, the daemon started, and the process enabled to start on boot.
7. Check that it’s running
  $ sudo systemctl status docker
...
~~~~~~~ Install Docker Desktop ~~~~~~~
//If not available, you can use https://app.docker.com
8. After the above you can now install Docker Desktop without downloading the .deb file
  $ sudo apt-get install docker-desktop
  // at the end it displays a download error, you can ignore it
  //For Upgrades, yuo need to download pckg and install again
9. Load Virtualization Support module manually, with KVM (if it didn't load automatically)
  $ modprobe kvm
10. Load the module for the corresponding processor
  $ modprobe kvm_intel  // depending on the processor,  modprobe kvm_amd
  // If there are any errors, check in Bios if Virtualization Support is Enabled
11. Check diagnostics if the above command fails
  $ kvm-ok
12. Check if the KVM modules are enabled
  $ lsmod | grep kvm
Set up KVM device user permissions
13. To check ownership of /dev/kvm
  $ ls -al /dev/kvm
14. Add your user to the kvm group in order to access the kvm device
  $ sudo usermod -aG kvm $USER
15. Sign out and sign back in so that your group membership is re-evaluated. Then Launch DD.

--- some Helpful Commands ---
+ Check the status of the docker service
	$ systemctl status docker
+ View information about the Docker engine
	$ docker info
+ (1)Start Docker Socket
	$ sudo systemctl start docker.socket
  **// The Docker socket is the Unix socket that enables the communication between the Docker client and Docker Daemon
+ (2)Start Docker
	$ sudo system start docker

~~~~~~~~~~    Notes     ~~~~~~~~~~
Ytube:TechWorld with Nana::19'
• Docker apps are built in layers
• Docker and Kernel are virtualization tools
• Docker virtalizaes the ApplicationLayer, and uses the host kernel
• VM virtualizes the whole OSkernel
• Docker Workflow
  + Docker Client: UserInterface for interacting with Docker; terminal or GUI
  + Docker Host(Daemon): Backgroudn process responsible for managing containers on the host system.
  + Docker Registry(DockerHub): is the centralized repositry of docker images

***• A running container can't be accessed right away because it is running in an Isolated Docker Network
	To access it, 1st we need to EXPOSE the Container to out localNetwork
	  We do this by PORT BINDING: bind the container's port to the host's port(to make the servce availbale to the outside world)
/* Standard ports for applications
   nginx, always runs on port 80
   redis, always runs on port 6379
*/
• Structure of DOCKERFILE
  + IS basically "The Definition" to use to Build a Docker image
  + Dockerfiles start from a parent image or "base image"
  + It is a Docker image that Your image will be based on
  + You choose the base image, depending on which tools you need to have available
	ie.: a lightweight linux -> on top of it: node, etc.
  + The FROM directive, is the beginning of every Dockerfile to call a {base image}
  + The RUN directive, is to run linux commands, to install dependencies
    *These commands are run in a shell inside the container environment
  + The COPY directive, is to copy files or directories from your local to the container
• Each instruction in the Dockerfile creates one layer, and they are stacked after eachother
  *eachone is a delta of the change from the previous layer
• Once built a recently created image, it gets preloaded on our local drive



---- CLI Commands ----
  $ docker [option] [command] [arguments]
  $ docker ps  , (Process Status) show running containers
  			-a  , (all) show all containers: stopped and running
  $ docker run postgres:10.10  , run a specific version of an image in a new container
  			-d  , (detached) flag to run the container in the background
  		* it doesn't need to previously pull, it auto pulls the image from docker if it doesn't find it locally
  			-p {hostPort:containerPort}  , (publish) publish a container's port to the host(any 4 digit port you choose)
  			* It is a standard to use the same port the container uses in the host
  			* Only one service can be run on a specific port on the host
  			--name  , assign a specific name to the container, for easier use
  			-e {PASS_VAR=mypass}  , to specify environment variables
  			--net {network name}  , to run the container in a specific container network
  			- v {"host/dir:container/dir"} , (volumes) to persist and/or share data between the host and the container
  			-i  , (interactive) it keeps the standard input (STDIN) open even if not attached, allowing you to interact with the container
  			-t  , (terminal) This flag allocates a pseudo-TTY (terminal). It provides a terminal interface for the container, making it easier to interact with command-line applications
  			//the 2 prev can be used together: -it
  	*/* When having many parameters in a CLI command we can separate them with "\" like:
  	  *	docker run -d \
	  * -p 27017:27017 \
	  * --name mongodb \
	  */ mongo
  	...    stop {container}  , stop one or more running containers
  	...    start {container}  , re-starts one or more recently created and stopped containers
  	...    rm  {container(s)}, removes created and stopped containers
  			-f  , force remove a running container
  	...    rmi {image(s)}  , remove a docker image
  	//remove image and related containers, automated
  	//docker rm $(docker ps -a -q --filter ancestor=[image]) && docker rmi [image]
	...    from  , specifies the base image to use for the new image
	...    workdir  , to set working directory
	...    copy  , copy files from build context to image
	...    run  , execute commands in the shell during image build; to create a container
	...    expose  , inform ports to use(listen to)
	...    env  , to set environment variables
	...    arg  , defines build time variables
	...    volume  , creates a mountpoint for externally mounted volumes (for ext storage)
	...    cmd  , provides default(flexible) commands to execute when the container starts
	...    entrypoint  , defines default(fixed) executable to run when the container starts
	...	   pull  , download and install an image on our machine
	...	   images  , lists the docker images pulled locally
	...    logs {container}  , shows the current logs of the container
* {container} , the container ID or Name can be used
	...    build  , to build a docker image from a dockerfile, specifying the directory
			-t  , to set a name and optionally a tag to the image, "name:tag" format
			.  , at the end, to specify where is the file located, . if in the current dir
			ie.: docker build -t nana-node-app:1.0 .
	...    exec  , to get a terminal from a container, to debug a container
			-it  , to run the Interactive Terminal
			ie.: docker exec -it (containerIdOrName) /bin/bash => docker exec -it CntID bash command
			*// check env variables with "env" as a command
			*// exit with "exit"
	...    network  , to work with Docker Networks
			ls  , to list all the available networks
			create {network-name}  , to create a new network
  $ cat /etc/issue  , to know the version of the linux system   //Ubuntu 22.04.5 LTS
  $ echo $XDG_CURRENT_DESKTOP  , to know which desktop environment I am using
  $ docker run -it ubuntu  , to create a container with the ubuntu image
  	-it  , is for 'interactive'
  	
---On Error: Cannot connect to the Docker daemon---
☢ Try 1st with priviledges
   > $ sudo docker pull ...
☢ check if docker is running
   > $ systemctl status docker
if it was on:
☢ add the current user to the docker group
   > $ sudo usermod -aG docker $USER   


---1.Example, 1st using docker---
• nginx, webserver with ui
1.- Find a docker image from DockerRegistries in DockerHub
2.- Select the tag of a desired file
3.- Pull the file in the terminal, with the desired version:
	//docker pull {imageName}:{tag} = pull an image from a registry
	$ docker pull nginx:1.23
3.1.- Check if it pulled the image correctly
	$ docker images
4.- Run the image in a container
	$ docker run nginx:1.23
5.- Check the running container list
	$ docker ps
6.- Stop the port(if it was run detached) and run it Binded/exposded to any desired local port
	$ docker run -d -p 80:80 nginx:1.23
	80 is the standard port nginx runs on, can be seen using $ docker ps
	and now the container can be accessed in a browser specifying thr port, localhost:9000

---2.Example, 1st creation of docker Image, to deploy---
We need to create a Definition of how to build an image from our application
It is created in a dockerfile, to create the dockerImage
- We'll use express.js to start an application on port 3000 that displays a message
example proy
> /root
  > src/
	> server.js
	> Dockerfile 
  > package.json


---- DockerFile Commands / Directives ----
  1☁ FROM , choose the BaseImage to build this image from
		And also can build other base libraries on top of it
		ie.: FROM (base lib):(base OS kernel)  =>  FROM node:19-alpine
  2☁ COPY , copy files&folders from our local and paste into the container
		ie.: COPY (what) (where) => COPY package.json /app/
		*// The slash at the end tells docker to create the Dir if it doesn't exist
		ie.: COPY src /app/
  3☁ WORKDIR , set the default location / dir for all following commands
		Like changing into a dir with 'cd ...' to start working
  4☁ RUN , will execute any command in a shell inside the container env
		ie.: RUN npm install
  5☁ CMD , instruction that is to be executed when the Docker container starts
		Last command in the file to start the application
		ie.: CMD ["command", "parameter"] => ["node", "server.js"]
Then we build our Docker Image with:
  > docker build -t nana-node-app:1.0 .
Then check if your image is up
  > docker images
Then run your image
  > docker run -d -p 3000:3000 nana-node-app:1.0
Check your app running in your localhost:3000
Check your logs with the id of your running container
 > docker logs 1a4971b5304c
View cointainer Id with
 > docker ps -a
 
---- to Debug a Container ----
To get a terminal of the container and maybe:
 - navigate to a directory inside
 - check the log file
 - check configuration
 - print out env variables
 we use:
	$ docker exec -it containerID /bin/bash


---- Docker Snippets ----
✔ --- VSCODE Instance ---
docker run -it --name code-server-4 -p 127.0.0.1:8080:8080 \
  -v "$HOME/.config:/home/coder/.config" \
  -v "$HOME/CODE/java:/home/coder/project" \
  -u "$(id -u):$(id -g)" \
  -e "DOCKER_USER=$USER" \
  codercom/code-server:latest
//the config.yaml file is created in $HOME/.config/code-server
//you can have presets for extensions...

// to run already created code-server container
docker start -i cc-code-server





----- Symbols ... -----
✔
←	→
☢
✿	♣	☁					ಠ_ರೃ			ಠ_ಠ
☆	❤										( ಠ ͜ʖ ರೃ)
△	Δ	▽						(ʘ‿ʘ)╯
α	β	ɛ	Ω	Σ							( ͡° ͜ʖ ͡°)
₿	✉︎	♮	π	♯				(ง ͠° ͟ʖ ͡°)ง
⚀ ⚁ ⚂ ⚃ ⚄ ⚅								୧༼ಠ益ಠ༽୨
